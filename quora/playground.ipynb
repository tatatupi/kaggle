{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "# from string import punctuation\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from TextToWord import text_to_wordlist\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf-8')\n",
    "\n",
    "########################################\n",
    "## set directories and parameters\n",
    "########################################\n",
    "BASE_DIR = '../quora/data/'\n",
    "EMBEDDING_FILE = BASE_DIR + 'GoogleNews-vectors-negative300.bin'\n",
    "TRAIN_DATA_FILE = BASE_DIR + 'train_aux.csv'\n",
    "TEST_DATA_FILE = BASE_DIR + 'test_aux.csv'\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "num_lstm = np.random.randint(175, 275)\n",
    "num_dense = np.random.randint(100, 150)\n",
    "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
    "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
    "\n",
    "act = 'relu'\n",
    "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set\n",
    "\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, rate_drop_dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors\n",
      "Found 3000000 word vectors of word2vec\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## index word vectors\n",
    "########################################\n",
    "print('Indexing word vectors')\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train dataset\n",
      "Found 37 texts in train.csv\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## process train texts in datasets\n",
    "########################################\n",
    "print('Processing train dataset')\n",
    "texts_1 = [] \n",
    "texts_2 = []\n",
    "labels = []\n",
    "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        texts_1.append(text_to_wordlist(values[3]))\n",
    "        texts_2.append(text_to_wordlist(values[4]))\n",
    "        labels.append(int(values[5]))\n",
    "print('Found %s texts in train.csv' % len(texts_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test dataset\n",
      "Found 21 texts in test.csv\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## process train texts in datasets\n",
    "########################################\n",
    "print('Processing test dataset')\n",
    "test_texts_1 = []\n",
    "test_texts_2 = []\n",
    "test_ids = []\n",
    "with codecs.open(TEST_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        if len(values) < 4:\n",
    "            test_texts_1.append(text_to_wordlist(values[1]))\n",
    "            test_texts_2.append(text_to_wordlist(values[2]))\n",
    "            test_ids.append(values[0])\n",
    "print('Found %s texts in test.csv' % len(test_texts_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 501 unique tokens\n",
      "Shape of data tensor: (37, 30)\n",
      "Shape of label tensor: (37,)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## tokenizing words\n",
    "########################################\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_1 + texts_2 + test_texts_1 + test_texts_2)\n",
    "\n",
    "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
    "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
    "test_sequences_1 = tokenizer.texts_to_sequences(test_texts_1)\n",
    "test_sequences_2 = tokenizer.texts_to_sequences(test_texts_2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(labels)\n",
    "print('Shape of data tensor:', data_1.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_ids = np.array(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix\n",
      "Null word embeddings: 37\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## prepare embeddings\n",
    "########################################\n",
    "print('Preparing embedding matrix')\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## sample train/validation data\n",
    "########################################\n",
    "#np.random.seed(1234)\n",
    "perm = np.random.permutation(len(data_1))\n",
    "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "data_1_train = np.vstack((data_1[idx_train], data_2[idx_train]))\n",
    "data_2_train = np.vstack((data_2[idx_train], data_1[idx_train]))\n",
    "labels_train = np.concatenate((labels[idx_train], labels[idx_train]))\n",
    "\n",
    "data_1_val = np.vstack((data_1[idx_val], data_2[idx_val]))\n",
    "data_2_val = np.vstack((data_2[idx_val], data_1[idx_val]))\n",
    "labels_val = np.concatenate((labels[idx_val], labels[idx_val]))\n",
    "\n",
    "weight_val = np.ones(len(labels_val))\n",
    "if re_weight:\n",
    "    weight_val *= 0.472001959\n",
    "    weight_val[labels_val==0] = 1.309028344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 300)      150600      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 270)          616680      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 540)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 540)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 540)          2160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 116)          62756       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 116)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 116)          464         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            117         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 832,777\n",
      "Trainable params: 680,865\n",
      "Non-trainable params: 151,912\n",
      "__________________________________________________________________________________________________\n",
      "lstm_270_116_0.20_0.18\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## define the model structure\n",
    "########################################\n",
    "embedding_layer = Embedding(nb_words,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False)\n",
    "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
    "\n",
    "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "merged = concatenate([x1, y1])\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "merged = Dense(num_dense, activation=act)(merged)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "########################################\n",
    "## add class weight\n",
    "########################################\n",
    "if re_weight:\n",
    "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
    "else:\n",
    "    class_weight = None\n",
    "\n",
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "model = Model(inputs=[sequence_1_input, sequence_2_input], \\\n",
    "        outputs=preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['acc'])\n",
    "model.summary()\n",
    "print(STAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"802pt\" viewBox=\"0.00 0.00 538.00 802.00\" width=\"538pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 798)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-798 534,-798 534,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139717331097248 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139717331097248</title>\n",
       "<polygon fill=\"none\" points=\"0,-747.5 0,-793.5 256,-793.5 256,-747.5 0,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-766.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"125,-747.5 125,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-770.5 180,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-747.5 180,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-778.3\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"180,-770.5 256,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-755.3\">(None, 30)</text>\n",
       "</g>\n",
       "<!-- 139717331096296 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139717331096296</title>\n",
       "<polygon fill=\"none\" points=\"105,-664.5 105,-710.5 425,-710.5 425,-664.5 105,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185.5\" y=\"-683.8\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"266,-664.5 266,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"266,-687.5 321,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"321,-664.5 321,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-695.3\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"321,-687.5 425,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-672.3\">(None, 30, 300)</text>\n",
       "</g>\n",
       "<!-- 139717331097248&#45;&gt;139717331096296 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139717331097248-&gt;139717331096296</title>\n",
       "<path d=\"M165.436,-747.366C181.897,-737.634 201.395,-726.106 218.754,-715.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"220.783,-718.709 227.609,-710.607 217.22,-712.683 220.783,-718.709\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139717331096632 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139717331096632</title>\n",
       "<polygon fill=\"none\" points=\"274,-747.5 274,-793.5 530,-793.5 530,-747.5 274,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-766.8\">input_2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"399,-747.5 399,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"399,-770.5 454,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"454,-747.5 454,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492\" y=\"-778.3\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"454,-770.5 530,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492\" y=\"-755.3\">(None, 30)</text>\n",
       "</g>\n",
       "<!-- 139717331096632&#45;&gt;139717331096296 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139717331096632-&gt;139717331096296</title>\n",
       "<path d=\"M364.564,-747.366C348.103,-737.634 328.605,-726.106 311.246,-715.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"312.78,-712.683 302.391,-710.607 309.217,-718.709 312.78,-712.683\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139717331095960 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139717331095960</title>\n",
       "<polygon fill=\"none\" points=\"136.5,-581.5 136.5,-627.5 393.5,-627.5 393.5,-581.5 136.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185.5\" y=\"-600.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"234.5,-581.5 234.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"234.5,-604.5 289.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"289.5,-581.5 289.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-612.3\">(None, 30, 300)</text>\n",
       "<polyline fill=\"none\" points=\"289.5,-604.5 393.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-589.3\">(None, 270)</text>\n",
       "</g>\n",
       "<!-- 139717331096296&#45;&gt;139717331095960 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139717331096296-&gt;139717331095960</title>\n",
       "<path d=\"M265,-664.366C265,-656.152 265,-646.658 265,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-637.607 265,-627.607 261.5,-637.607 268.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139717330917416 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139717330917416</title>\n",
       "<polygon fill=\"none\" points=\"71,-498.5 71,-544.5 459,-544.5 459,-498.5 71,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-517.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"239,-498.5 239,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"239,-521.5 294,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"294,-498.5 294,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-529.3\">[(None, 270), (None, 270)]</text>\n",
       "<polyline fill=\"none\" points=\"294,-521.5 459,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-506.3\">(None, 540)</text>\n",
       "</g>\n",
       "<!-- 139717331095960&#45;&gt;139717330917416 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139717331095960-&gt;139717330917416</title>\n",
       "<path d=\"M265,-581.366C265,-573.152 265,-563.658 265,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-554.607 265,-544.607 261.5,-554.607 268.5,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139722569210680 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139722569210680</title>\n",
       "<polygon fill=\"none\" points=\"133.5,-415.5 133.5,-461.5 396.5,-461.5 396.5,-415.5 133.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-434.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"258.5,-415.5 258.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"258.5,-438.5 313.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"313.5,-415.5 313.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-446.3\">(None, 540)</text>\n",
       "<polyline fill=\"none\" points=\"313.5,-438.5 396.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-423.3\">(None, 540)</text>\n",
       "</g>\n",
       "<!-- 139717330917416&#45;&gt;139722569210680 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139717330917416-&gt;139722569210680</title>\n",
       "<path d=\"M265,-498.366C265,-490.152 265,-480.658 265,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-471.607 265,-461.607 261.5,-471.607 268.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139717389741864 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139717389741864</title>\n",
       "<polygon fill=\"none\" points=\"66,-332.5 66,-378.5 464,-378.5 464,-332.5 66,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-351.8\">batch_normalization_1: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"326,-332.5 326,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"326,-355.5 381,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"381,-332.5 381,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"422.5\" y=\"-363.3\">(None, 540)</text>\n",
       "<polyline fill=\"none\" points=\"381,-355.5 464,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"422.5\" y=\"-340.3\">(None, 540)</text>\n",
       "</g>\n",
       "<!-- 139722569210680&#45;&gt;139717389741864 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139722569210680-&gt;139717389741864</title>\n",
       "<path d=\"M265,-415.366C265,-407.152 265,-397.658 265,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-388.607 265,-378.607 261.5,-388.607 268.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139717348133968 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139717348133968</title>\n",
       "<polygon fill=\"none\" points=\"145,-249.5 145,-295.5 385,-295.5 385,-249.5 145,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-268.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"247,-249.5 247,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"247,-272.5 302,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"302,-249.5 302,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-280.3\">(None, 540)</text>\n",
       "<polyline fill=\"none\" points=\"302,-272.5 385,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-257.3\">(None, 116)</text>\n",
       "</g>\n",
       "<!-- 139717389741864&#45;&gt;139717348133968 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139717389741864-&gt;139717348133968</title>\n",
       "<path d=\"M265,-332.366C265,-324.152 265,-314.658 265,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-305.607 265,-295.607 261.5,-305.607 268.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139718512582440 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139718512582440</title>\n",
       "<polygon fill=\"none\" points=\"133.5,-166.5 133.5,-212.5 396.5,-212.5 396.5,-166.5 133.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-185.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"258.5,-166.5 258.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"258.5,-189.5 313.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"313.5,-166.5 313.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-197.3\">(None, 116)</text>\n",
       "<polyline fill=\"none\" points=\"313.5,-189.5 396.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-174.3\">(None, 116)</text>\n",
       "</g>\n",
       "<!-- 139717348133968&#45;&gt;139718512582440 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139717348133968-&gt;139718512582440</title>\n",
       "<path d=\"M265,-249.366C265,-241.152 265,-231.658 265,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-222.607 265,-212.607 261.5,-222.607 268.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139717334915000 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139717334915000</title>\n",
       "<polygon fill=\"none\" points=\"66,-83.5 66,-129.5 464,-129.5 464,-83.5 66,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-102.8\">batch_normalization_2: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"326,-83.5 326,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"326,-106.5 381,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"381,-83.5 381,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"422.5\" y=\"-114.3\">(None, 116)</text>\n",
       "<polyline fill=\"none\" points=\"381,-106.5 464,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"422.5\" y=\"-91.3\">(None, 116)</text>\n",
       "</g>\n",
       "<!-- 139718512582440&#45;&gt;139717334915000 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139718512582440-&gt;139717334915000</title>\n",
       "<path d=\"M265,-166.366C265,-158.152 265,-148.658 265,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-139.607 265,-129.607 261.5,-139.607 268.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139717333953056 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139717333953056</title>\n",
       "<polygon fill=\"none\" points=\"145,-0.5 145,-46.5 385,-46.5 385,-0.5 145,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-19.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"247,-0.5 247,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"247,-23.5 302,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"302,-0.5 302,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-31.3\">(None, 116)</text>\n",
       "<polyline fill=\"none\" points=\"302,-23.5 385,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"343.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 139717334915000&#45;&gt;139717333953056 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>139717334915000-&gt;139717333953056</title>\n",
       "<path d=\"M265,-83.3664C265,-75.1516 265,-65.6579 265,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268.5,-56.6068 265,-46.6068 261.5,-56.6069 268.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66 samples, validate on 8 samples\n",
      "Epoch 1/200\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0522 - acc: 1.0000 - val_loss: 1.3935 - val_acc: 0.2500\n",
      "Epoch 2/200\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0586 - acc: 1.0000 - val_loss: 1.2276 - val_acc: 0.2500\n",
      "Epoch 3/200\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0356 - acc: 1.0000 - val_loss: 1.2572 - val_acc: 0.2500\n",
      "Epoch 4/200\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0281 - acc: 1.0000 - val_loss: 1.2799 - val_acc: 0.2500\n",
      "Epoch 5/200\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0266 - acc: 1.0000 - val_loss: 1.3779 - val_acc: 0.2500\n",
      "Epoch 6/200\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0246 - acc: 1.0000 - val_loss: 1.3678 - val_acc: 0.2500\n",
      "Epoch 7/200\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.0217 - acc: 1.0000 - val_loss: 1.3553 - val_acc: 0.2500\n",
      "Epoch 8/200\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.3655 - val_acc: 0.2500\n",
      "Epoch 9/200\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 1.4941 - val_acc: 0.2500\n",
      "Epoch 10/200\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.6018 - val_acc: 0.2500\n",
      "Epoch 11/200\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.5983 - val_acc: 0.2500\n",
      "Epoch 12/200\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.6001 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "bst_model_path = STAMP + '.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "tensorboard_callback = TensorBoard('./logs/')\n",
    "\n",
    "hist = model.fit([data_1_train, data_2_train], labels_train, \\\n",
    "        validation_data=([data_1_val, data_2_val], labels_val, weight_val), \\\n",
    "        epochs=200, batch_size=2048, shuffle=True, \\\n",
    "        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(bst_model_path)\n",
    "bst_val_score = min(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8130847215652466"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_val_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
